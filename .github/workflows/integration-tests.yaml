name: Integration Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      test_environment:
        description: 'Test environment to use'
        required: true
        default: 'kind'
        type: choice
        options:
        - kind
        - staging

env:
  ANSIBLE_FORCE_COLOR: 1
  ANSIBLE_HOST_KEY_CHECKING: false
  KIND_VERSION: v0.20.0
  KUBECTL_VERSION: v1.28.0
  HELM_VERSION: v3.13.0

jobs:
  setup-test-env:
    name: Setup Test Environment
    runs-on: ubuntu-latest
    outputs:
      cluster-name: ${{ steps.setup.outputs.cluster-name }}
      kubeconfig: ${{ steps.setup.outputs.kubeconfig }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Kind
        uses: helm/kind-action@v1.8.0
        with:
          version: ${{ env.KIND_VERSION }}
          kubectl_version: ${{ env.KUBECTL_VERSION }}
          cluster_name: integration-test
          config: |
            kind: Cluster
            apiVersion: kind.x-k8s.io/v1alpha4
            nodes:
            - role: control-plane
              kubeadmConfigPatches:
              - |
                kind: InitConfiguration
                nodeRegistration:
                  kubeletExtraArgs:
                    node-labels: "ingress-ready=true"
              extraPortMappings:
              - containerPort: 80
                hostPort: 80
                protocol: TCP
              - containerPort: 443
                hostPort: 443
                protocol: TCP
            - role: worker
            - role: worker

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: ${{ env.HELM_VERSION }}

      - name: Setup cluster info
        id: setup
        run: |
          echo "cluster-name=integration-test" >> $GITHUB_OUTPUT
          echo "kubeconfig=$HOME/.kube/config" >> $GITHUB_OUTPUT

      - name: Verify cluster setup
        run: |
          kubectl get nodes
          kubectl cluster-info

  test-k3s-components:
    name: Test K3s Components
    runs-on: ubuntu-latest
    needs: setup-test-env
    strategy:
      matrix:
        component:
          - ingress-nginx
          - metallb
          - cert-manager
          - longhorn
          - argocd
          - monitoring
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Kind
        uses: helm/kind-action@v1.8.0
        with:
          version: ${{ env.KIND_VERSION }}
          kubectl_version: ${{ env.KUBECTL_VERSION }}
          cluster_name: ${{ needs.setup-test-env.outputs.cluster-name }}

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: ${{ env.HELM_VERSION }}

      - name: Add Helm repositories
        run: |
          case "${{ matrix.component }}" in
            "ingress-nginx")
              helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
              ;;
            "metallb")
              helm repo add metallb https://metallb.github.io/metallb
              ;;
            "cert-manager")
              helm repo add jetstack https://charts.jetstack.io
              ;;
            "longhorn")
              helm repo add longhorn https://charts.longhorn.io
              ;;
            "argocd")
              helm repo add argo https://argoproj.github.io/argo-helm
              ;;
            "monitoring")
              helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
              ;;
          esac
          helm repo update

      - name: Install component
        run: |
          case "${{ matrix.component }}" in
            "ingress-nginx")
              helm install ingress-nginx ingress-nginx/ingress-nginx \
                --namespace ingress-nginx \
                --create-namespace \
                --set controller.service.type=NodePort \
                --wait --timeout=300s
              ;;
            "metallb")
              helm install metallb metallb/metallb \
                --namespace metallb-system \
                --create-namespace \
                --wait --timeout=300s
              ;;
            "cert-manager")
              helm install cert-manager jetstack/cert-manager \
                --namespace cert-manager \
                --create-namespace \
                --set installCRDs=true \
                --wait --timeout=300s
              ;;
            "longhorn")
              # Skip Longhorn in Kind (requires specific setup)
              echo "Skipping Longhorn installation in Kind environment"
              exit 0
              ;;
            "argocd")
              helm install argocd argo/argo-cd \
                --namespace argocd \
                --create-namespace \
                --wait --timeout=600s
              ;;
            "monitoring")
              helm install monitoring prometheus-community/kube-prometheus-stack \
                --namespace monitoring \
                --create-namespace \
                --set grafana.service.type=NodePort \
                --set prometheus.service.type=NodePort \
                --wait --timeout=600s
              ;;
          esac

      - name: Test component functionality
        run: |
          case "${{ matrix.component }}" in
            "ingress-nginx")
              kubectl wait --namespace ingress-nginx \
                --for=condition=ready pod \
                --selector=app.kubernetes.io/component=controller \
                --timeout=300s
              kubectl get pods -n ingress-nginx
              ;;
            "metallb")
              kubectl wait --namespace metallb-system \
                --for=condition=ready pod \
                --selector=app=metallb \
                --timeout=300s
              kubectl get pods -n metallb-system
              ;;
            "cert-manager")
              kubectl wait --namespace cert-manager \
                --for=condition=ready pod \
                --selector=app.kubernetes.io/instance=cert-manager \
                --timeout=300s
              kubectl get pods -n cert-manager
              ;;
            "longhorn")
              echo "Longhorn test skipped"
              ;;
            "argocd")
              kubectl wait --namespace argocd \
                --for=condition=ready pod \
                --selector=app.kubernetes.io/part-of=argocd \
                --timeout=600s
              kubectl get pods -n argocd
              ;;
            "monitoring")
              kubectl wait --namespace monitoring \
                --for=condition=ready pod \
                --selector=app.kubernetes.io/name=prometheus \
                --timeout=600s
              kubectl get pods -n monitoring
              ;;
          esac

  test-gitops-workflow:
    name: Test GitOps Workflow
    runs-on: ubuntu-latest
    needs: setup-test-env
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Kind
        uses: helm/kind-action@v1.8.0
        with:
          version: ${{ env.KIND_VERSION }}
          kubectl_version: ${{ env.KUBECTL_VERSION }}
          cluster_name: ${{ needs.setup-test-env.outputs.cluster-name }}

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: ${{ env.HELM_VERSION }}

      - name: Install ArgoCD
        run: |
          helm repo add argo https://argoproj.github.io/argo-helm
          helm repo update
          helm install argocd argo/argo-cd \
            --namespace argocd \
            --create-namespace \
            --wait --timeout=600s

      - name: Create test application
        run: |
          # Create test app directory structure
          mkdir -p test-app/{base,environments/test}
          
          # Create test Helm chart
          cat > test-app/base/Chart.yaml << EOF
          apiVersion: v2
          name: test-app
          description: Test Application
          type: application
          version: 0.1.0
          appVersion: "1.0.0"
          EOF
          
          cat > test-app/base/values.yaml << EOF
          replicaCount: 1
          image:
            repository: nginx
            tag: alpine
            pullPolicy: IfNotPresent
          service:
            type: ClusterIP
            port: 80
          EOF
          
          cat > test-app/base/templates/deployment.yaml << EOF
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: test-app
          spec:
            replicas: {{ .Values.replicaCount }}
            selector:
              matchLabels:
                app: test-app
            template:
              metadata:
                labels:
                  app: test-app
              spec:
                containers:
                - name: test-app
                  image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
                  ports:
                  - containerPort: 80
          EOF
          
          cat > test-app/base/templates/service.yaml << EOF
          apiVersion: v1
          kind: Service
          metadata:
            name: test-app
          spec:
            type: {{ .Values.service.type }}
            ports:
            - port: {{ .Values.service.port }}
              targetPort: 80
            selector:
              app: test-app
          EOF

      - name: Create ArgoCD Application
        run: |
          # Wait for ArgoCD to be ready
          kubectl wait --namespace argocd \
            --for=condition=ready pod \
            --selector=app.kubernetes.io/name=argocd-server \
            --timeout=600s
          
          # Create application manifest
          cat > argocd-test-app.yaml << EOF
          apiVersion: argoproj.io/v1alpha1
          kind: Application
          metadata:
            name: test-app
            namespace: argocd
          spec:
            project: default
            source:
              repoURL: https://github.com/nginxinc/kubernetes-ingress
              targetRevision: HEAD
              path: examples/simple
            destination:
              server: https://kubernetes.default.svc
              namespace: test-app
            syncPolicy:
              automated:
                prune: true
                selfHeal: true
              syncOptions:
                - CreateNamespace=true
          EOF
          
          kubectl apply -f argocd-test-app.yaml

      - name: Verify GitOps deployment
        run: |
          # Wait for application to sync
          sleep 60
          
          # Check application status
          kubectl get applications -n argocd
          
          # Verify test application is deployed
          kubectl get pods -n test-app || echo "Test app namespace not found"

  test-ansible-playbooks:
    name: Test Ansible Playbooks
    runs-on: ubuntu-latest
    needs: setup-test-env
    strategy:
      matrix:
        playbook:
          - site.yml
          - k3s-setup.yml
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Ansible and dependencies
        run: |
          pip install --upgrade pip
          pip install ansible ansible-lint molecule[docker]
          ansible-galaxy install -r infrastructure/requirements.yml || true

      - name: Create test inventory
        run: |
          mkdir -p test-inventory
          cat > test-inventory/hosts.yml << EOF
          all:
            children:
              k3s_cluster:
                children:
                  control_plane:
                    hosts:
                      control-1:
                        ansible_host: 127.0.0.1
                        ansible_connection: local
                  workers:
                    hosts:
                      worker-1:
                        ansible_host: 127.0.0.1
                        ansible_connection: local
          EOF

      - name: Validate Ansible syntax
        run: |
          cd infrastructure
          case "${{ matrix.playbook }}" in
            "site.yml")
              ansible-playbook --syntax-check -i ../test-inventory/hosts.yml playbooks/site.yml
              ;;
            "k3s-setup.yml")
              ansible-playbook --syntax-check -i ../test-inventory/hosts.yml playbooks/k3s-setup.yml
              ;;
          esac

      - name: Run Ansible lint
        run: |
          cd infrastructure
          case "${{ matrix.playbook }}" in
            "site.yml")
              ansible-lint playbooks/site.yml || true
              ;;
            "k3s-setup.yml")
              ansible-lint playbooks/k3s-setup.yml || true
              ;;
          esac

      - name: Test playbook in check mode
        run: |
          cd infrastructure
          case "${{ matrix.playbook }}" in
            "site.yml")
              ansible-playbook --check -i ../test-inventory/hosts.yml playbooks/site.yml || echo "Check mode completed with warnings"
              ;;
            "k3s-setup.yml")
              ansible-playbook --check -i ../test-inventory/hosts.yml playbooks/k3s-setup.yml || echo "Check mode completed with warnings"
              ;;
          esac

  test-monitoring-stack:
    name: Test Monitoring Stack
    runs-on: ubuntu-latest
    needs: setup-test-env
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Kind
        uses: helm/kind-action@v1.8.0
        with:
          version: ${{ env.KIND_VERSION }}
          kubectl_version: ${{ env.KUBECTL_VERSION }}
          cluster_name: ${{ needs.setup-test-env.outputs.cluster-name }}

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: ${{ env.HELM_VERSION }}

      - name: Install Prometheus Stack
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update
          helm install monitoring prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --create-namespace \
            --set grafana.service.type=NodePort \
            --set prometheus.service.type=NodePort \
            --set grafana.adminPassword=admin123 \
            --wait --timeout=600s

      - name: Test Prometheus connectivity
        run: |
          kubectl wait --namespace monitoring \
            --for=condition=ready pod \
            --selector=app.kubernetes.io/name=prometheus \
            --timeout=300s
          
          kubectl port-forward -n monitoring svc/monitoring-prometheus-server 9090:9090 &
          sleep 10
          curl -f http://localhost:9090/-/healthy || echo "Prometheus health check failed"

      - name: Test Grafana connectivity
        run: |
          kubectl wait --namespace monitoring \
            --for=condition=ready pod \
            --selector=app.kubernetes.io/name=grafana \
            --timeout=300s
          
          kubectl port-forward -n monitoring svc/monitoring-grafana 3000:80 &
          sleep 10
          curl -f http://localhost:3000/api/health || echo "Grafana health check failed"

      - name: Verify metrics collection
        run: |
          kubectl port-forward -n monitoring svc/monitoring-prometheus-server 9090:9090 &
          sleep 10
          
          # Test basic metrics query
          curl -s "http://localhost:9090/api/v1/query?query=up" | jq '.status' | grep success || echo "Metrics query failed"

  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Scan Kubernetes manifests
        run: |
          # Install kubesec
          curl -sSX GET "https://api.github.com/repos/controlplaneio/kubesec/releases/latest" \
            | jq -r '.assets[] | select(.name | test("linux_amd64")) | .browser_download_url' \
            | xargs curl -sSL -o kubesec
          chmod +x kubesec
          
          # Scan any Kubernetes manifests
          find . -name "*.yaml" -path "*/k8s/*" -exec ./kubesec scan {} \; || echo "No k8s manifests found to scan"

  integration-summary:
    name: Integration Test Summary
    runs-on: ubuntu-latest
    needs: [test-k3s-components, test-gitops-workflow, test-ansible-playbooks, test-monitoring-stack, security-scan]
    if: always()
    steps:
      - name: Generate test report
        run: |
          echo "## Integration Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| K3s Components | ${{ needs.test-k3s-components.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| GitOps Workflow | ${{ needs.test-gitops-workflow.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Ansible Playbooks | ${{ needs.test-ansible-playbooks.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Monitoring Stack | ${{ needs.test-monitoring-stack.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Scan | ${{ needs.security-scan.result }} |" >> $GITHUB_STEP_SUMMARY

      - name: Check overall result
        run: |
          if [[ "${{ needs.test-k3s-components.result }}" == "success" && \
                "${{ needs.test-gitops-workflow.result }}" == "success" && \
                "${{ needs.test-ansible-playbooks.result }}" == "success" && \
                "${{ needs.test-monitoring-stack.result }}" == "success" && \
                "${{ needs.security-scan.result }}" == "success" ]]; then
            echo "✅ All integration tests passed!"
            exit 0
          else
            echo "❌ One or more integration tests failed!"
            exit 1
          fi 