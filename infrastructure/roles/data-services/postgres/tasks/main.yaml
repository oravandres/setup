---
- name: Label nodes for optimal PostgreSQL placement
  shell: |
    # Label the PC node (assuming it's the x86 master)
    PC_NODE=$(kubectl get nodes -o wide --no-headers | grep -v arm64 | grep -v aarch64 | head -1 | awk '{print $1}')
    if [ ! -z "$PC_NODE" ]; then
      kubectl label nodes $PC_NODE node-type=pc --overwrite
      kubectl label nodes $PC_NODE postgres-preferred=true --overwrite
    fi
    
    # Label Pi nodes
    kubectl get nodes -o wide --no-headers | grep -E 'arm64|aarch64' | while read line; do
      NODE=$(echo $line | awk '{print $1}')
      kubectl label nodes $NODE node-type=raspberry-pi --overwrite
      kubectl label nodes $NODE postgres-preferred=false --overwrite
    done
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  changed_when: false

- name: Create namespace for PostgreSQL
  kubernetes.core.k8s:
    name: postgres
    api_version: v1
    kind: Namespace
    state: present
    kubeconfig: /etc/rancher/k3s/k3s.yaml

- name: Add Bitnami repository
  kubernetes.core.helm_repository:
    name: bitnami
    repo_url: https://charts.bitnami.com/bitnami

- name: Create PostgreSQL HA values configuration
  copy:
    content: |
      # PostgreSQL HA configuration optimized for heterogeneous cluster (1 PC + 6 Pis)
      
      # Global configuration
      global:
        postgresql:
          auth:
            postgresPassword: "postgres123"  # Change in production!
            username: "appuser"
            password: "appuser123"  # Change in production!
            database: "appdb"
            replicationUsername: "replicator"
            replicationPassword: "replicator123"  # Change in production!
        storageClass: "local-path"
      
      # PostgreSQL Primary configuration
      postgresql:
        # HA setup with 1 primary + 2 read replicas
        replicaCount: 1  # Primary instance
        
        # Resource limits optimized for Pi 4B 8GB but capable on PC
        resources:
          limits:
            cpu: 2000m      # Can use more on PC
            memory: 3Gi     # Reasonable for 8GB Pi
          requests:
            cpu: 500m       # Ensures scheduling on Pi
            memory: 1Gi     # Conservative start
        
        # PostgreSQL configuration
        postgresqlConfiguration:
          max_connections: "100"
          shared_buffers: "256MB"
          effective_cache_size: "1GB"
          maintenance_work_mem: "64MB"
          checkpoint_completion_target: "0.9"
          wal_buffers: "16MB"
          default_statistics_target: "100"
          random_page_cost: "1.1"
          effective_io_concurrency: "200"
          work_mem: "8MB"
          min_wal_size: "1GB"
          max_wal_size: "4GB"
          max_worker_processes: "4"
          max_parallel_workers_per_gather: "2"
          max_parallel_workers: "4"
          max_parallel_maintenance_workers: "2"
        
        # Storage configuration
        persistence:
          enabled: true
          size: 100Gi  # Reasonable for 500GB storage
          storageClass: "local-path"
          accessModes:
            - ReadWriteOnce
        
        # Node affinity - prefer PC for primary
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 80  # Strong preference for PC
                preference:
                  matchExpressions:
                    - key: kubernetes.io/arch
                      operator: In
                      values: ["amd64"]
              - weight: 60  # Prefer nodes labeled as postgres-preferred
                preference:
                  matchExpressions:
                    - key: postgres-preferred
                      operator: In
                      values: ["true"]
        
        # Pod disruption budget
        podDisruptionBudget:
          create: true
          minAvailable: 1
        
        # Tolerations for mixed architecture
        tolerations:
          - key: "arm"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"
          - key: "node.kubernetes.io/arch"
            operator: "Equal"
            value: "arm64"
            effect: "NoSchedule"
      
      # PostgreSQL Read Replicas configuration
      readReplicas:
        # 2 read replicas for HA
        replicaCount: 2
        
        # Resource limits for read replicas (can be lighter)
        resources:
          limits:
            cpu: 1500m
            memory: 2Gi
          requests:
            cpu: 300m
            memory: 768Mi
        
        # Storage for read replicas
        persistence:
          enabled: true
          size: 50Gi  # Smaller than primary
          storageClass: "local-path"
          accessModes:
            - ReadWriteOnce
        
        # Distribution affinity - spread across nodes
        affinity:
          nodeAffinity:
            # Can run on any node but prefer different from primary
            preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 50
                preference:
                  matchExpressions:
                    - key: kubernetes.io/arch
                      operator: In
                      values: ["amd64", "arm64"]
          # Anti-affinity to distribute replicas
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                      - key: app.kubernetes.io/name
                        operator: In
                        values: ["postgresql"]
                      - key: app.kubernetes.io/component
                        operator: In
                        values: ["read"]
                  topologyKey: kubernetes.io/hostname
        
        # Tolerations for mixed architecture
        tolerations:
          - key: "arm"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"
          - key: "node.kubernetes.io/arch"
            operator: "Equal"
            value: "arm64"
            effect: "NoSchedule"
      
      # Pgpool configuration (Connection pooling and load balancing)
      pgpool:
        # Enable Pgpool for connection pooling and load balancing
        enabled: true
        replicaCount: 2  # HA setup for Pgpool
        
        # Resource limits for Pgpool (lightweight)
        resources:
          limits:
            cpu: 500m
            memory: 512Mi
          requests:
            cpu: 200m
            memory: 256Mi
        
        # Pgpool configuration
        configuration:
          listenAddresses: "*"
          port: 5432
          socketDir: "/opt/bitnami/pgpool/tmp"
          pcp_listen_addresses: "*"
          pcp_port: 9898
          pcp_socket_dir: "/opt/bitnami/pgpool/tmp"
          listen_backlog_multiplier: 2
          serialize_accept: off
          child_life_time: 300
          child_max_connections: 0
          connection_life_time: 0
          client_idle_limit: 0
          max_pool: 4
          num_init_children: 32
          max_connections: 100
        
        # Anti-affinity for Pgpool instances
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                      - key: app.kubernetes.io/name
                        operator: In
                        values: ["postgresql"]
                      - key: app.kubernetes.io/component
                        operator: In
                        values: ["pgpool"]
                  topologyKey: kubernetes.io/hostname
        
        # Tolerations for mixed architecture
        tolerations:
          - key: "arm"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"
          - key: "node.kubernetes.io/arch"
            operator: "Equal"
            value: "arm64"
            effect: "NoSchedule"
      
      # Metrics and monitoring
      metrics:
        enabled: true
        
        # Prometheus PostgreSQL exporter
        serviceMonitor:
          enabled: true
          namespace: "monitoring"  # If you have monitoring namespace
        
        # Resource limits for metrics
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
      
      # Backup configuration (optional)
      backup:
        enabled: false  # Can be enabled later with proper storage backend
      
      # Network Policies (optional, for security)
      networkPolicy:
        enabled: false  # Can be enabled for production
      
      # Service configuration
      service:
        type: ClusterIP
        ports:
          postgresql: 5432
    dest: /tmp/postgresql-ha-values.yaml
    mode: '0644'

- name: Deploy PostgreSQL HA with custom configuration
  kubernetes.core.helm:
    name: my-postgres-ha
    chart_ref: bitnami/postgresql-ha
    release_namespace: postgres
    create_namespace: true
    values_files:
      - /tmp/postgresql-ha-values.yaml
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    wait: true
    timeout: 15m

- name: Verify PostgreSQL primary deployment
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Pod
    namespace: postgres
    label_selectors:
      - app.kubernetes.io/name=postgresql
      - app.kubernetes.io/component=postgresql
    kubeconfig: /etc/rancher/k3s/k3s.yaml
  register: postgres_primary_pods
  until: postgres_primary_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length >= 1
  retries: 20
  delay: 30

- name: Verify PostgreSQL read replicas deployment
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Pod
    namespace: postgres
    label_selectors:
      - app.kubernetes.io/name=postgresql
      - app.kubernetes.io/component=read
    kubeconfig: /etc/rancher/k3s/k3s.yaml
  register: postgres_replica_pods
  until: postgres_replica_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length >= 1
  retries: 20
  delay: 30

- name: Verify Pgpool deployment
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Pod
    namespace: postgres
    label_selectors:
      - app.kubernetes.io/name=postgresql
      - app.kubernetes.io/component=pgpool
    kubeconfig: /etc/rancher/k3s/k3s.yaml
  register: pgpool_pods
  until: pgpool_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length >= 1
  retries: 15
  delay: 30

- name: Verify HA distribution - Check PostgreSQL pods are on different nodes
  shell: |
    kubectl get pods -n postgres -l app.kubernetes.io/name=postgresql -o wide --no-headers | awk '{print $7}' | sort | uniq | wc -l
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  register: unique_postgres_nodes
  failed_when: unique_postgres_nodes.stdout | int < 2

- name: Create PostgreSQL NodePort service for external access
  kubernetes.core.k8s:
    definition:
      apiVersion: v1
      kind: Service
      metadata:
        name: postgres-nodeport
        namespace: postgres
        labels:
          app.kubernetes.io/name: postgresql
      spec:
        type: NodePort
        ports:
          - port: 5432
            targetPort: 5432
            nodePort: 30432
            protocol: TCP
            name: postgresql
        selector:
          app.kubernetes.io/name: postgresql
          app.kubernetes.io/component: pgpool
    kubeconfig: /etc/rancher/k3s/k3s.yaml

- name: Get node information for connection details
  shell: kubectl get nodes -o wide --no-headers | head -1 | awk '{print $6}'
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
  register: node_ip
  changed_when: false

- name: Display PostgreSQL HA status
  debug:
    msg: |
      ‚úÖ PostgreSQL HA Status:
      - Primary pods running: {{ postgres_primary_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length }}
      - Read replica pods running: {{ postgres_replica_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length }}
      - Pgpool pods running: {{ pgpool_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length }}
      - Nodes used: {{ unique_postgres_nodes.stdout }}
      - HA Level: {{ 'TRUE HA' if (postgres_primary_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length >= 1 and postgres_replica_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length >= 2 and unique_postgres_nodes.stdout | int >= 2) else 'PARTIAL HA' if (postgres_primary_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length >= 1 and postgres_replica_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length >= 1) else 'NO HA' }}
      
      üåê Connection Details:
      - External Access: {{ node_ip.stdout }}:30432
      - Internal Service: my-postgres-ha-postgresql-ha-pgpool.postgres.svc.cluster.local:5432
      - Primary Service: my-postgres-ha-postgresql-ha-postgresql.postgres.svc.cluster.local:5432
      - Read Service: my-postgres-ha-postgresql-ha-postgresql-read.postgres.svc.cluster.local:5432
      
      üîê Default Credentials:
      - Admin User: postgres / postgres123
      - App User: appuser / appuser123
      - Database: appdb
      
      üìä Architecture:
      - 1x Primary PostgreSQL (read/write)
      - 2x Read Replicas (read-only)
      - 2x Pgpool (connection pooling & load balancing)
      - Automatic failover enabled
      - Streaming replication configured

- name: Test database connectivity
  shell: |
    kubectl exec -n postgres $(kubectl get pods -n postgres -l app.kubernetes.io/component=postgresql --no-headers | head -1 | awk '{print $1}') -- psql -U appuser -d appdb -c "SELECT version();"
  environment:
    KUBECONFIG: /etc/rancher/k3s/k3s.yaml
    PGPASSWORD: "appuser123"
  register: db_test
  ignore_errors: true

- name: Display database test result
  debug:
    msg: |
      üß™ Database Connectivity Test:
      {{ 'SUCCESS - Database is accessible' if db_test.rc == 0 else 'PENDING - Database may still be initializing' }}
      {% if db_test.rc == 0 %}
      Version: {{ db_test.stdout_lines[0] if db_test.stdout_lines else 'Unknown' }}
      {% endif %}

- name: Clean up temporary values file
  file:
    path: /tmp/postgresql-ha-values.yaml
    state: absent
